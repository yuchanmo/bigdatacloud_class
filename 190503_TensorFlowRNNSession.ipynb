{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlowRNNSession.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "s97fwEOoiXk3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwlPAA8ZJUsr",
        "colab_type": "text"
      },
      "source": [
        "Copyright (C) 2019 Software Platform Lab, Seoul National University\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
        "\n",
        "you may not use this file except in compliance with the License. \n",
        "\n",
        "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 \n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software \n",
        "\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS, \n",
        "\n",
        "\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
        "\n",
        "\n",
        "See the License for the specific language governing permissions and\n",
        "\n",
        "\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDNSc2_nJex1",
        "colab_type": "text"
      },
      "source": [
        "**Colab 101**\n",
        "\n",
        "Colab is a free Jupyter notebook environment offered by Google Research. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNB9n-BkhIEC",
        "colab_type": "toc"
      },
      "source": [
        ">[3-4. RNN](#scrollTo=Ki_RHIwPJvyn)\n",
        "\n",
        ">>[Recurrent neural network](#scrollTo=s97fwEOoiXk3)\n",
        "\n",
        ">>[LSTM](#scrollTo=8p7tgEPijeSd)\n",
        "\n",
        ">>[Prepare PTB dataset](#scrollTo=V5N1npMVQqJz)\n",
        "\n",
        ">>[Define input preprocessing functions](#scrollTo=xrE4WkZNUn9o)\n",
        "\n",
        ">>>[Quiz 1](#scrollTo=cnNhG69dgWsA)\n",
        "\n",
        ">>>[Quiz 2](#scrollTo=piRAhFIGGRc_)\n",
        "\n",
        ">>[Build RNN model](#scrollTo=a4UKKwwsZa4I)\n",
        "\n",
        ">>>[Setting hyperparameters](#scrollTo=5zhtEo46Hatf)\n",
        "\n",
        ">>>[Word embeddings](#scrollTo=M8UKfIQ8FdFy)\n",
        "\n",
        ">>>[Quiz 3](#scrollTo=sGJ_-LgwIige)\n",
        "\n",
        ">>>[Define RNN graph](#scrollTo=SWyh4MHCtgJ4)\n",
        "\n",
        ">>>[Quiz 4](#scrollTo=HJbfZ_i8xUf7)\n",
        "\n",
        ">>>[Define loss](#scrollTo=9Vyd8rYE7JTv)\n",
        "\n",
        ">>>[Define optimizer(train_op)](#scrollTo=Lpb3sfKO7MA7)\n",
        "\n",
        ">>[Run RNN model](#scrollTo=MA_-1EhV8hSr)\n",
        "\n",
        ">>[Visualize using TensorBoard](#scrollTo=C7FK5eg_4WCy)\n",
        "\n",
        ">>>[Preparation: Setting Up TensorBoard](#scrollTo=2_oD0_sK5hm6)\n",
        "\n",
        ">>>[Visualize the graph](#scrollTo=trtXkJsH6i6i)\n",
        "\n",
        ">>[Visualize the perplexity](#scrollTo=Dy-9kJge87po)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki_RHIwPJvyn",
        "colab_type": "text"
      },
      "source": [
        "#3-4. RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s97fwEOoiXk3",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent neural network\n",
        "\n",
        "\n",
        "*   Learn sequential data\n",
        "*   Ex. prediction of a word after a partial sentence, understanding of the current scene in a video based on previous scences\n",
        "\n",
        "![RNN cell](https://drive.google.com/uc?id=1hvEtbzjuT8hxBtNNTrBRMxthCcfFN5FG) \n",
        "출처: https://colah.github.io/posts/2015-08-Understanding-LSTMs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p7tgEPijeSd",
        "colab_type": "text"
      },
      "source": [
        "## LSTM\n",
        "\n",
        "\n",
        "* Gradient vanishing problem: during backpropagation, as gradient is calculated by chain rule, the final grandient becomes almost zero\n",
        "* Long short-term memory: solves gradient vanishing problem and handles long-term dependencies\n",
        "![LSTM](https://drive.google.com/uc?id=1W9JKubIgJoyvzQy4U8KGNQWcVziu_6fT)\n",
        "출처: https://colah.github.io/posts/2015-08-Understanding-LSTMs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hjLLUbrYwyO",
        "colab_type": "text"
      },
      "source": [
        "Let's learn simple LSTM model for language modeling. The code comes from [TF-RNN tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5N1npMVQqJz",
        "colab_type": "text"
      },
      "source": [
        "##  Prepare PTB dataset\n",
        "\n",
        "PTB is dataset widely used for natural language processing(NLP). It annotates syntactic or semantic label as a tree structure. A leaf node is matching to a word. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFZ3bfVsQz_p",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "a12676dc-37dd-4366-90ca-329173bc94fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1745
        }
      },
      "source": [
        "#@title Click to download PTB\n",
        "!rm -rf data*\n",
        "!rm -rf simple-examples*\n",
        "!wget http://www.fit.vutbr.cz/%7Eimikolov/rnnlm/simple-examples.tgz\n",
        "!tar -xzvf simple-examples.tgz\n",
        "!mv simple-examples/data ./\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-03 07:20:26--  http://www.fit.vutbr.cz/%7Eimikolov/rnnlm/simple-examples.tgz\n",
            "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
            "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34869662 (33M) [application/x-gtar]\n",
            "Saving to: ‘simple-examples.tgz’\n",
            "\n",
            "simple-examples.tgz 100%[===================>]  33.25M  4.02MB/s    in 9.1s    \n",
            "\n",
            "2019-05-03 07:20:35 (3.64 MB/s) - ‘simple-examples.tgz’ saved [34869662/34869662]\n",
            "\n",
            "./\n",
            "./simple-examples/\n",
            "./simple-examples/data/\n",
            "./simple-examples/data/ptb.test.txt\n",
            "./simple-examples/data/ptb.train.txt\n",
            "./simple-examples/data/ptb.valid.txt\n",
            "./simple-examples/data/README\n",
            "./simple-examples/data/ptb.char.train.txt\n",
            "./simple-examples/data/ptb.char.test.txt\n",
            "./simple-examples/data/ptb.char.valid.txt\n",
            "./simple-examples/models/\n",
            "./simple-examples/models/swb.ngram.model\n",
            "./simple-examples/models/swb.rnn.model\n",
            "./simple-examples/models/README\n",
            "./simple-examples/rnnlm-0.2b/\n",
            "./simple-examples/rnnlm-0.2b/CHANGE.log\n",
            "./simple-examples/rnnlm-0.2b/FAQ.txt\n",
            "./simple-examples/rnnlm-0.2b/convert.c\n",
            "./simple-examples/rnnlm-0.2b/makefile\n",
            "./simple-examples/rnnlm-0.2b/rnnlm.cpp\n",
            "./simple-examples/rnnlm-0.2b/rnnlmlib.cpp\n",
            "./simple-examples/rnnlm-0.2b/rnnlmlib.h\n",
            "./simple-examples/rnnlm-0.2b/prob.c\n",
            "./simple-examples/rnnlm-0.2b/test\n",
            "./simple-examples/rnnlm-0.2b/train\n",
            "./simple-examples/rnnlm-0.2b/valid\n",
            "./simple-examples/rnnlm-0.2b/example.sh\n",
            "./simple-examples/rnnlm-0.2b/example.output\n",
            "./simple-examples/rnnlm-0.2b/COPYRIGHT.txt\n",
            "./simple-examples/1-train/\n",
            "./simple-examples/1-train/train.sh\n",
            "./simple-examples/1-train/test.sh\n",
            "./simple-examples/1-train/README\n",
            "./simple-examples/3-combination/\n",
            "./simple-examples/3-combination/train.sh\n",
            "./simple-examples/3-combination/test.sh\n",
            "./simple-examples/3-combination/README\n",
            "./simple-examples/2-nbest-rescore/\n",
            "./simple-examples/2-nbest-rescore/lattices/\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_127040_127488.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_127513_127835.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_127865_128175.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_128188_128447.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_128490_129032.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/nbest.sh\n",
            "./simple-examples/2-nbest-rescore/lattices/nbest/\n",
            "./simple-examples/2-nbest-rescore/lattices/latlist\n",
            "./simple-examples/2-nbest-rescore/README\n",
            "./simple-examples/2-nbest-rescore/getbest.c\n",
            "./simple-examples/2-nbest-rescore/gettext.c\n",
            "./simple-examples/2-nbest-rescore/makenbest.c\n",
            "./simple-examples/2-nbest-rescore/makenbest\n",
            "./simple-examples/2-nbest-rescore/gettext\n",
            "./simple-examples/2-nbest-rescore/getbest\n",
            "./simple-examples/5-one-iter/\n",
            "./simple-examples/5-one-iter/test.sh\n",
            "./simple-examples/5-one-iter/train.sh\n",
            "./simple-examples/5-one-iter/README\n",
            "./simple-examples/6-recovery-during-training/\n",
            "./simple-examples/6-recovery-during-training/test.sh\n",
            "./simple-examples/6-recovery-during-training/train.sh\n",
            "./simple-examples/6-recovery-during-training/README\n",
            "./simple-examples/7-dynamic-evaluation/\n",
            "./simple-examples/7-dynamic-evaluation/test.sh\n",
            "./simple-examples/7-dynamic-evaluation/train.sh\n",
            "./simple-examples/7-dynamic-evaluation/README\n",
            "./simple-examples/temp/\n",
            "./simple-examples/8-direct/\n",
            "./simple-examples/8-direct/train.sh\n",
            "./simple-examples/8-direct/test.sh\n",
            "./simple-examples/8-direct/README\n",
            "./simple-examples/4-data-generation/\n",
            "./simple-examples/4-data-generation/train.sh\n",
            "./simple-examples/4-data-generation/test.sh\n",
            "./simple-examples/4-data-generation/README\n",
            "./simple-examples/9-char-based-lm/\n",
            "./simple-examples/9-char-based-lm/test.sh\n",
            "./simple-examples/9-char-based-lm/train.sh\n",
            "./simple-examples/9-char-based-lm/README\n",
            "data  ngrok\t\t\t    sample_data      simple-examples.tgz\n",
            "log   ngrok-stable-linux-amd64.zip  simple-examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrE4WkZNUn9o",
        "colab_type": "text"
      },
      "source": [
        "## Define input preprocessing functions\n",
        "\n",
        "\n",
        "*   Mapping a word into an identifer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drceRvn4VGec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "\"\"\"Utilities for parsing PTB text files.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "Py3 = sys.version_info[0] == 3\n",
        "\n",
        "def _read_words(filename):\n",
        "  with tf.gfile.GFile(filename, \"r\") as f:\n",
        "    if Py3:\n",
        "      return f.read().replace(\"\\n\", \"<eos>\").split()\n",
        "    else:\n",
        "      return f.read().decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()\n",
        "\n",
        "\n",
        "def _build_vocab(filename):\n",
        "  data = _read_words(filename)\n",
        "\n",
        "  counter = collections.Counter(data)\n",
        "  count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "  words, _ = list(zip(*count_pairs))\n",
        "  word_to_id = dict(zip(words, range(len(words))))\n",
        "\n",
        "  return word_to_id\n",
        "\n",
        "\n",
        "def _file_to_word_ids(filename, word_to_id):\n",
        "  data = _read_words(filename)\n",
        "  return [word_to_id[word] for word in data if word in word_to_id]\n",
        "\n",
        "\n",
        "def ptb_raw_data(data_path=None):\n",
        "  \"\"\"Load PTB raw data from data directory \"data_path\".\n",
        "\n",
        "  Reads PTB text files, converts strings to integer ids,\n",
        "  and performs mini-batching of the inputs.\n",
        "\n",
        "  The PTB dataset comes from Tomas Mikolov's webpage:\n",
        "\n",
        "  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
        "\n",
        "  Args:\n",
        "    data_path: string path to the directory where simple-examples.tgz has\n",
        "      been extracted.\n",
        "\n",
        "  Returns:\n",
        "    tuple (train_data, valid_data, test_data, vocabulary)\n",
        "    where each of the data objects can be passed to PTBIterator.\n",
        "  \"\"\"\n",
        "\n",
        "  train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
        "  valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
        "  test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
        "\n",
        "  word_to_id = _build_vocab(train_path)\n",
        "  train_data = _file_to_word_ids(train_path, word_to_id)\n",
        "  valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
        "  test_data = _file_to_word_ids(test_path, word_to_id)\n",
        "  vocabulary = len(word_to_id)\n",
        "  return train_data, valid_data, test_data, vocabulary\n",
        "\n",
        "\n",
        "def ptb_producer(raw_data, batch_size, num_steps, name=None):\n",
        "  \"\"\"Iterate on the raw PTB data.\n",
        "\n",
        "  This chunks up raw_data into batches of examples and returns Tensors that\n",
        "  are drawn from these batches.\n",
        "\n",
        "  Args:\n",
        "    raw_data: one of the raw data outputs from ptb_raw_data.\n",
        "    batch_size: int, the batch size.\n",
        "    num_steps: int, the number of unrolls.\n",
        "    name: the name of this operation (optional).\n",
        "\n",
        "  Returns:\n",
        "    A pair of Tensors, each shaped [batch_size, num_steps]. The second element\n",
        "    of the tuple is the same data time-shifted to the right by one.\n",
        "\n",
        "  Raises:\n",
        "    tf.errors.InvalidArgumentError: if batch_size or num_steps are too high.\n",
        "  \"\"\"\n",
        "  with tf.name_scope(name, \"PTBProducer\", [raw_data, batch_size, num_steps]):\n",
        "    raw_data = tf.convert_to_tensor(raw_data, name=\"raw_data\", dtype=tf.int32)\n",
        "\n",
        "    data_len = tf.size(raw_data)\n",
        "    batch_len = data_len // batch_size\n",
        "    data = tf.reshape(raw_data[0 : batch_size * batch_len],\n",
        "                      [batch_size, batch_len])\n",
        "\n",
        "    epoch_size = (batch_len - 1) // num_steps\n",
        "    assertion = tf.assert_positive(\n",
        "        epoch_size,\n",
        "        message=\"epoch_size == 0, decrease batch_size or num_steps\")\n",
        "    with tf.control_dependencies([assertion]):\n",
        "      epoch_size = tf.identity(epoch_size, name=\"epoch_size\")\n",
        "\n",
        "    i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()\n",
        "    x = tf.strided_slice(data, [0, i * num_steps],\n",
        "                         [batch_size, (i + 1) * num_steps])\n",
        "    x.set_shape([batch_size, num_steps])\n",
        "    y = tf.strided_slice(data, [0, i * num_steps + 1],\n",
        "                         [batch_size, (i + 1) * num_steps + 1])\n",
        "    y.set_shape([batch_size, num_steps])\n",
        "    return x, y\n",
        "  \n",
        "class PTBInput(object):\n",
        "    \"\"\"The input data.\"\"\"\n",
        "\n",
        "    def __init__(self, config, data, name=None):\n",
        "      self.batch_size = batch_size = config.batch_size\n",
        "      self.num_steps = num_steps = config.num_steps\n",
        "      self.epoch_size = ((len(data) // batch_size) - 1) // num_steps\n",
        "      self.input_data, self.targets = ptb_producer(\n",
        "          data, batch_size, num_steps, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cnNhG69dgWsA"
      },
      "source": [
        "### Quiz 1\n",
        "Find the identifier of the word \"market\" using the defined functions above. (data_path='data')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QZyw665-gWsE",
        "outputId": "56c1f5ff-8e3b-4e5a-95e7-90f5b4c7e28d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "data_path='data'\n",
        "train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
        "word_to_id = _build_vocab(train_path)\n",
        "print(word_to_id['market'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piRAhFIGGRc_",
        "colab_type": "text"
      },
      "source": [
        "### Quiz 2\n",
        "Guess how many words in x or y of ptb_producer when \n",
        "**batch_size=2 and num_steps=5.**\n",
        "Then check it yourself.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X37jTic3HZM9",
        "colab_type": "code",
        "outputId": "74ba8a09-53e6-4f24-dd64-69e55015db73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "data_path='data'\n",
        "train_data, _, _, _ = ptb_raw_data(data_path)\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # Fill below\n",
        "    x,y = ptb_producer(train_data,2,5)\n",
        "    with tf.Session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      tf.train.start_queue_runners(sess=sess)\n",
        "      print(sess.run(x))\n",
        "      print(sess.run(y))\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-2995e37eb0a5>:106: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-33941e65be31>:9: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "[[9970 9971 9972 9974 9975]\n",
            " [1969    0   98   89 2254]]\n",
            "[[9980 9981 9982 9983 9984]\n",
            " [ 312 1641    4 1063    8]]\n",
            "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
            "\t [[{{node PTBProducer/input_producer/input_producer_EnqueueMany}}]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfJS1FYghuA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "9d6a35ba-b84d-40f1-b2e1-d22c5538d5bc"
      },
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"PTBProducer/StridedSlice:0\", shape=(2, 5), dtype=int32)\n",
            "Tensor(\"PTBProducer/StridedSlice_1:0\", shape=(2, 5), dtype=int32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread QueueRunnerThread-PTBProducer/input_producer-PTBProducer/input_producer/input_producer_EnqueueMany:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
            "    enqueue_callable()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
            "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
            "\t [[{{node PTBProducer/input_producer/input_producer_EnqueueMany}}]]\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4UKKwwsZa4I",
        "colab_type": "text"
      },
      "source": [
        "## Build RNN model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zhtEo46Hatf",
        "colab_type": "text"
      },
      "source": [
        "### Setting hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19MkDHgFHh5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MediumConfig(object):\n",
        "  \"\"\"Medium config.\"\"\"\n",
        "  init_scale = 0.05\n",
        "  learning_rate = 1.0\n",
        "  max_grad_norm = 5\n",
        "  num_layers = 2\n",
        "  num_steps = 35\n",
        "  hidden_size = 650\n",
        "  max_epoch = 6\n",
        "  max_max_epoch = 39\n",
        "  keep_prob = 0.5\n",
        "  lr_decay = 0.8\n",
        "  batch_size = 20\n",
        "  vocab_size = 10000\n",
        "   \n",
        "config = MediumConfig()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8UKfIQ8FdFy",
        "colab_type": "text"
      },
      "source": [
        "### Word embeddings \n",
        "Convert word ids to vector representations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHJMzr9KFYvX",
        "colab_type": "code",
        "outputId": "8c738072-dfd9-43b0-8912-9aa8deea7939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "def inputs(input):\n",
        "    size = config.hidden_size\n",
        "    vocab_size = config.vocab_size\n",
        "    with tf.device(\"/cpu:0\"):\n",
        "      embedding = tf.get_variable(\n",
        "          \"embedding\", [vocab_size, size])\n",
        "      inputs = tf.nn.embedding_lookup(embedding, input.input_data)\n",
        "\n",
        "      inputs = tf.nn.dropout(inputs, config.keep_prob)\n",
        "      return inputs\n",
        "  \n",
        "with tf.Graph().as_default():\n",
        "    data_path = 'data'\n",
        "    raw_data = ptb_raw_data(data_path)\n",
        "    train_data, valid_data, test_data, _ = raw_data\n",
        "    train_input = PTBInput(config=config, data=train_data, name=\"TrainInput\")\n",
        "    print(inputs(train_input))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-7-df66786eb9b5>:9: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"dropout/mul:0\", shape=(20, 35, 650), dtype=float32, device=/device:CPU:0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGJ_-LgwIige",
        "colab_type": "text"
      },
      "source": [
        "### Quiz 3\n",
        "Guess the tensor shape of output of embedding lookup when reading embedding for wordIDs=[3, 9, 20] (vocab_size=100, embedding_size=4)\n",
        "\n",
        "Then check it yourself. \n",
        "What happens if wordIs=[3,9,200] if other conditions are the same?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee8ZoxmXKgI8",
        "colab_type": "code",
        "outputId": "ce7e4cbf-a6b5-4514-e644-485ee7768771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "vocab_size = 100\n",
        "embedding_size = 4\n",
        "with tf.Graph().as_default():\n",
        "  wordIDs=tf.placeholder(dtype=tf.int32)\n",
        "  embedding=tf.get_variable(\"embedding\",[vocab_size,embedding_size])\n",
        "  lookup = tf.nn.embedding_lookup(embedding,wordIDs)\n",
        "  sess = tf.Session() \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(lookup,feed_dict={wordIDs:[3,9,20]}))\n",
        "  print(sess.run(lookup,feed_dict={wordIDs:[3,9,20]}))\n",
        "  # Fill below\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.00571907  0.16578987  0.05818084  0.05671334]\n",
            " [ 0.02451965  0.15589058 -0.0014375  -0.22457291]\n",
            " [-0.05039348 -0.12316238 -0.08555493  0.19126329]]\n",
            "[[ 0.00571907  0.16578987  0.05818084  0.05671334]\n",
            " [ 0.02451965  0.15589058 -0.0014375  -0.22457291]\n",
            " [-0.05039348 -0.12316238 -0.08555493  0.19126329]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWyh4MHCtgJ4",
        "colab_type": "text"
      },
      "source": [
        "### Define RNN graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOAEPevotxtT",
        "colab_type": "code",
        "outputId": "6001a975-57ae-4c49-b8b1-e484e8a6a942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "def build_rnn_graph_lstm(inputs, config, is_training=True):\n",
        "    \"\"\"Build the inference graph using canonical LSTM cells.\"\"\"\n",
        "    # Slightly better results can be obtained with forget gate biases\n",
        "    # initialized to 1 but the hyperparameters of the model would need to be\n",
        "    # different than reported in the paper.\n",
        "    def make_cell():\n",
        "      cell = tf.contrib.rnn.BasicLSTMCell(\n",
        "          config.hidden_size, forget_bias=0.0, state_is_tuple=True,\n",
        "          reuse=not is_training)\n",
        "      if is_training and config.keep_prob < 1:\n",
        "        cell = tf.contrib.rnn.DropoutWrapper(\n",
        "            cell, output_keep_prob=config.keep_prob)\n",
        "      return cell\n",
        "\n",
        "    # Stacking multiple LSTMs\n",
        "    cell = tf.contrib.rnn.MultiRNNCell(\n",
        "        [make_cell() for _ in range(config.num_layers)], state_is_tuple=True)\n",
        "\n",
        "    initial_state = cell.zero_state(config.batch_size, tf.float32)\n",
        "    state = initial_state\n",
        "    # Simplified version of tf.nn.static_rnn().\n",
        "    # This builds an unrolled LSTM for tutorial purposes only.\n",
        "    # In general, use tf.nn.static_rnn() or tf.nn.static_state_saving_rnn().\n",
        "    #\n",
        "    # The alternative version of the code below is:\n",
        "    #\n",
        "    # inputs = tf.unstack(inputs, num=self.num_steps, axis=1)\n",
        "    # outputs, state = tf.nn.static_rnn(cell, inputs,\n",
        "    #                                   initial_state=self._initial_state)\n",
        "    outputs = []\n",
        "    with tf.variable_scope(\"RNN\"):\n",
        "      for time_step in range(config.num_steps):\n",
        "        if time_step > 0: tf.get_variable_scope().reuse_variables()\n",
        "        (cell_output, state) = cell(inputs[:, time_step, :], state)\n",
        "        outputs.append(cell_output)\n",
        "    output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])\n",
        "    return output, state, initial_state\n",
        "  \n",
        "  \n",
        "with tf.Graph().as_default():\n",
        "    data_path = 'data'\n",
        "    raw_data = ptb_raw_data(data_path)\n",
        "    train_data, valid_data, test_data, _ = raw_data\n",
        "    train_input = PTBInput(config=config, data=train_data, name=\"TrainInput\")\n",
        "    inputs_ = inputs(train_input)\n",
        "    \n",
        "    output, final_state, initial_state = build_rnn_graph_lstm(inputs_, config)\n",
        "    print(output)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-9c02cce59e1c>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-12-9c02cce59e1c>:17: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "Tensor(\"Reshape:0\", shape=(700, 650), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJbfZ_i8xUf7",
        "colab_type": "text"
      },
      "source": [
        "### Quiz 4\n",
        "Define a single layer GRU RNN graph with the length of RNN cells as 10 (num_steps=10). \n",
        "\n",
        "**HINT: use `tf.nn.rnn_cell.GRUCell(config.hidden_size)`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9UT8axlxT6U",
        "colab_type": "code",
        "outputId": "52ad6655-a00d-4d3b-9910-d0f8b4001a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "def build_rnn_graph_GRU(inputs, config, is_training=True):\n",
        "    # Fill this function\n",
        "    def make_cell():\n",
        "      cell = tf.nn.rnn_cell.GRUCell(config.hidden_size,reuse=not is_training)\n",
        "      if is_training and config.keep_prob < 1:\n",
        "        cell = tf.contrib.rnn.DropoutWrapper(\n",
        "            cell, output_keep_prob=config.keep_prob)\n",
        "      return cell\n",
        "\n",
        "    cell = make_cell()\n",
        "    \n",
        "    initial_state = cell.zero_state(config.batch_size, tf.float32)\n",
        "    state = initial_state\n",
        "    \n",
        "    outputs = []\n",
        "    with tf.variable_scope(\"RNN\"):\n",
        "      for time_step in range(config.num_steps):\n",
        "        if time_step > 0: tf.get_variable_scope().reuse_variables()\n",
        "        (cell_output, state) = cell(inputs[:, time_step, :], state)\n",
        "        outputs.append(cell_output)\n",
        "    output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])\n",
        "    return output, state, initial_state\n",
        "\n",
        "num_steps = 10\n",
        "new_config = MediumConfig()\n",
        "new_config.num_steps = num_steps\n",
        "with tf.Graph().as_default():\n",
        "    data_path = 'data'\n",
        "    raw_data = ptb_raw_data(data_path)\n",
        "    train_data, valid_data, test_data, _ = raw_data\n",
        "    train_input = PTBInput(config=new_config, data=train_data, name=\"TrainInput\")\n",
        "    \n",
        "    output, final_state, initial_state  = build_rnn_graph_GRU(inputs(train_input), new_config)\n",
        "    print(output)\n",
        "          "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-340d7ca9321c>:4: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "Tensor(\"Reshape:0\", shape=(200, 650), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vyd8rYE7JTv",
        "colab_type": "text"
      },
      "source": [
        "### Define loss \n",
        "`tf.contrib.seq2seq.sequence_loss`: Weighted cross-entropy loss for a sequence of logits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuTA70pg7Lnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(config, input_, output):\n",
        "  softmax_w = tf.get_variable(\n",
        "        \"softmax_w\", [config.hidden_size, config.vocab_size], tf.float32)\n",
        "  softmax_b = tf.get_variable(\"softmax_b\", [config.vocab_size], tf.float32)\n",
        "  logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
        "  # Reshape logits to be a 3-D tensor for sequence loss\n",
        "  logits = tf.reshape(logits, [config.batch_size, config.num_steps, config.vocab_size])\n",
        "\n",
        "  # Use the contrib sequence loss and average over the batches\n",
        "  loss = tf.contrib.seq2seq.sequence_loss(\n",
        "        logits,\n",
        "        input_.targets,\n",
        "        tf.ones([config.batch_size, config.num_steps], tf.float32),\n",
        "        average_across_timesteps=False,\n",
        "        average_across_batch=True)\n",
        "   \n",
        "  cost = tf.reduce_sum(loss)\n",
        "  return cost\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpb3sfKO7MA7",
        "colab_type": "text"
      },
      "source": [
        "### Define optimizer(train_op)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95L51-rZ7Oc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimizer(cost):\n",
        "  tvars = tf.trainable_variables()\n",
        "  # 특정 iteration 에서 haunting 안되게 해서 전체적으로 특정 iteration에 의한 학습 실패를방지할 때 사용 하는거란다.\n",
        "  grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),\n",
        "                                    config.max_grad_norm)\n",
        "  optimizer = tf.train.GradientDescentOptimizer(1.0)\n",
        "  train_op = optimizer.apply_gradients(\n",
        "        zip(grads, tvars),\n",
        "        global_step=tf.train.get_or_create_global_step())\n",
        "  return train_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA_-1EhV8hSr",
        "colab_type": "text"
      },
      "source": [
        "## Run RNN model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMiIbwC78j-E",
        "colab_type": "code",
        "outputId": "3e386a79-2b81-4220-889f-8c89c1f65e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def define_graph(config):\n",
        "  data_path = 'data'\n",
        "  raw_data = ptb_raw_data(data_path)\n",
        "  train_data, valid_data, test_data, _ = raw_data\n",
        "  train_input = PTBInput(config=config, data=train_data, name=\"TrainInput\")\n",
        "  initializer = tf.random_uniform_initializer(-config.init_scale,\n",
        "                                              config.init_scale)\n",
        "  with tf.variable_scope(\"Model\", reuse=None, initializer=initializer):\n",
        "      output, final_state, initial_state = build_rnn_graph_lstm(inputs(train_input), config)\n",
        "    \n",
        "      cost = loss(config, train_input, output)\n",
        "      train_op = optimizer(cost)\n",
        "  return cost, initial_state, final_state, train_op\n",
        "      \n",
        "def run(sess, cost, initial_state, final_state, train_op):\n",
        "  init = tf.global_variables_initializer()\n",
        "  tf.train.start_queue_runners(sess=sess)\n",
        "  sess.run(init)\n",
        "    \n",
        "  state = sess.run(initial_state)\n",
        "    \n",
        "  costs = 0.0\n",
        "  iters = 0\n",
        "  start_time = time.time()\n",
        "  for step in range(1500):\n",
        "      feed_dict = {}\n",
        "      for i, (c, h) in enumerate(initial_state):\n",
        "        feed_dict[c] = state[i].c\n",
        "        feed_dict[h] = state[i].h\n",
        "      \n",
        "      cost_, state, _ = sess.run((cost, final_state, train_op), feed_dict=feed_dict)\n",
        "      costs += cost_\n",
        "      iters += config.num_steps\n",
        "      \n",
        "      if step % 150 == 0:\n",
        "         print(\"step:%d perplexity: %.3f speed: %.0f wps\" %\n",
        "            (step, np.exp(costs / iters),\n",
        "             iters * config.batch_size /\n",
        "             (time.time() - start_time)))\n",
        "\n",
        "\n",
        "config =  MediumConfig()\n",
        "with tf.Graph().as_default():\n",
        "    cost, initial_state, final_state, train_op = define_graph(config)\n",
        "   \n",
        "    sess = tf.Session()\n",
        "    run(sess, cost, initial_state, final_state, train_op)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "step:0 perplexity: 9999.885 speed: 1025 wps\n",
            "step:150 perplexity: 1144.049 speed: 10589 wps\n",
            "step:300 perplexity: 808.168 speed: 10963 wps\n",
            "step:450 perplexity: 649.722 speed: 11069 wps\n",
            "step:600 perplexity: 556.796 speed: 11093 wps\n",
            "step:750 perplexity: 490.870 speed: 11078 wps\n",
            "step:900 perplexity: 441.449 speed: 11079 wps\n",
            "step:1050 perplexity: 407.333 speed: 11058 wps\n",
            "step:1200 perplexity: 376.908 speed: 11031 wps\n",
            "step:1350 perplexity: 354.444 speed: 11017 wps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7FK5eg_4WCy",
        "colab_type": "text"
      },
      "source": [
        "## Visualize using TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_oD0_sK5hm6",
        "colab_type": "text"
      },
      "source": [
        "### Preparation: Setting Up TensorBoard\n",
        "This setting is only for colab (you don't need to know the details). If you use command line instead of colab, you can just use **'tensorboard --logdir=<logdir> --port=<port>'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcJ21Ydw6HPl",
        "colab_type": "code",
        "outputId": "0c93d8fc-669b-4e3f-f6a4-a366dccaea01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#download and unzip ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-03 07:32:44--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.73.94.166, 52.2.175.150, 3.209.102.29, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.73.94.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14991793 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  86%[================>   ]  12.33M  61.6MB/s               \rngrok-stable-linux- 100%[===================>]  14.30M  65.6MB/s    in 0.2s    \n",
            "\n",
            "2019-05-03 07:32:44 (65.6 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [14991793/14991793]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH0DBF4S6KFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run tensorboard\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "#run ngrok\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trtXkJsH6i6i",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHqkk2Ha6oTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config =  MediumConfig()\n",
        "with tf.Graph().as_default():\n",
        "    define_graph(config)\n",
        "    \n",
        "    writer = tf.summary.FileWriter('./log', tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrggWUhU64ji",
        "colab_type": "code",
        "outputId": "bae758a5-3c1e-4264-f552-9d63698e8a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#get the URL for tensorboard\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://9c803642.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy-9kJge87po",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgVD6KeM9Ig-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_with_summary(sess, cost, initial_state, final_state, train_op):\n",
        "  writer = tf.summary.FileWriter('./log', tf.get_default_graph())\n",
        "  init = tf.global_variables_initializer()\n",
        "  tf.train.start_queue_runners(sess=sess)\n",
        "  sess.run(init)\n",
        "    \n",
        "  state = sess.run(initial_state)\n",
        "    \n",
        "  costs = 0.0\n",
        "  iters = 0\n",
        "  start_time = time.time()\n",
        "  for step in range(1500):\n",
        "      feed_dict = {}\n",
        "      for i, (c, h) in enumerate(initial_state):\n",
        "        feed_dict[c] = state[i].c\n",
        "        feed_dict[h] = state[i].h\n",
        "      \n",
        "      cost_, state, _ = sess.run((cost, final_state, train_op), feed_dict=feed_dict)\n",
        "      costs += cost_\n",
        "      iters += config.num_steps\n",
        "      \n",
        "      #add summary\n",
        "      perplexity_summ = tf.Summary()\n",
        "      perplexity_summ.value.add(\n",
        "        tag='perplexity', simple_value=np.exp(costs/iters))\n",
        "      \n",
        "      writer.add_summary(perplexity_summ, step)\n",
        "      if step % 150 == 0:\n",
        "         print(\"step:%d perplexity: %.3f speed: %.0f wps\" %\n",
        "            (step, np.exp(costs / iters),\n",
        "             iters * config.batch_size /\n",
        "             (time.time() - start_time)))\n",
        "          \n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgEZ8t0L9DZc",
        "colab_type": "code",
        "outputId": "f4724c91-4857-4f5c-a5c0-e2442551eccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "\n",
        "config =  MediumConfig()\n",
        "with tf.Graph().as_default():\n",
        "    cost, initial_state, final_state, train_op = define_graph(config)\n",
        "   \n",
        "    sess = tf.Session()\n",
        "    run_with_summary(sess, cost, initial_state, final_state, train_op)\n",
        "    \n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step:0 perplexity: 9990.830 speed: 1701 wps\n",
            "step:150 perplexity: 1203.123 speed: 10548 wps\n",
            "step:300 perplexity: 835.977 speed: 10756 wps\n",
            "step:450 perplexity: 665.731 speed: 10817 wps\n",
            "step:600 perplexity: 568.895 speed: 10850 wps\n",
            "step:750 perplexity: 500.004 speed: 10856 wps\n",
            "step:900 perplexity: 448.743 speed: 10861 wps\n",
            "step:1050 perplexity: 413.395 speed: 10842 wps\n",
            "step:1200 perplexity: 382.214 speed: 10838 wps\n",
            "step:1350 perplexity: 359.225 speed: 10845 wps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iaOLDwPnts4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}