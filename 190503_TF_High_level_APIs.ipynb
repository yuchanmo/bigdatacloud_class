{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF High-level APIs.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKVeLItnS5uV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "Copyright (C) 2019 Software Platform Lab, Seoul National University\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
        "\n",
        "you may not use this file except in compliance with the License. \n",
        "\n",
        "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 \n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software \n",
        "\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS, \n",
        "\n",
        "\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
        "\n",
        "\n",
        "See the License for the specific language governing permissions and\n",
        "\n",
        "\n",
        "limitations under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2a_poedgfpI",
        "colab_type": "text"
      },
      "source": [
        "# TF High Level APIs\n",
        "TensorFlow provides high level APIs to define and execute neural network more easily. In this session, we will take a look at two of them: Keras and Eager execution.\n",
        "\n",
        "## 1. Keras (tf.keras)\n",
        "Keras is a high-level API to build and train deep learning models. It's used for fast prototyping, advanced research, and production, with three key advantages:\n",
        "\n",
        "- **User friendly**: Keras has a simple, consistent interface optimized for common use cases. It provides clear and actionable feedback for user errors.\n",
        "- **Modular and composable**: Keras models are made by connecting configurable building blocks together, with few restrictions.\n",
        "- **Easy to extend**: Write custom building blocks to express new ideas for research. Create new layers, loss functions, and develop state-of-the-art models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR4oMDv4siyO",
        "colab_type": "text"
      },
      "source": [
        "### Defining a model\n",
        "Keras API is accessible in the `tf.keras` namespace. Let's take a look how we can define a model using Keras API.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpJTfmFwZFAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuuQnUMipNX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "c77c04e0-d84e-474a-db4c-bda2eeda1a85"
      },
      "source": [
        "\n",
        "# Let's build a stack of *sequential* layers, which is\n",
        "# the most common form of neural network graphs.\n",
        "model = tf.keras.Sequential() \n",
        "\n",
        "# Adds a densely-connected layer with 64 units to the model\n",
        "model.add(layers.Dense(units=64, activation='relu', input_shape=(32,)))\n",
        "\n",
        "# Adds another layer, which has L2 regularization applied to the kernel matrix\n",
        "model.add(layers.Dense(units=64, kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "\n",
        "# Adds a softmax layer with 10 output units\n",
        "model.add(layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4SmnPgAbVAS",
        "colab_type": "text"
      },
      "source": [
        "If you visit https://www.tensorflow.org/api_docs/python/tf/keras/layers, you can find the supported layers, for example, Conv2D, BatchNormalization, LSTM, MaxPool, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJq7I5kOc1H-",
        "colab_type": "text"
      },
      "source": [
        "### Setting up training\n",
        "After the model is constructed, `compile` method configures how to learn the model, which allows us to specify the following:\n",
        "* `optimizer`: This field specifies which optimizer to use. We can pass an optimizer instance (e.g., `tf.train.AdamOptimizer`, `tf.train.RMSPropOptimizer`), which are defined in  `tf.train` module.\n",
        "* `loss`: The function to minimize during optimization. Common choices include `mean square error (mse)`, `[categorical|binary]_crossentropy`. Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module.\n",
        "* `metrics`: Used to monitor training. We can put string names or callables defined in `tf.keras.metrics` module (e.g. `'accuracy'`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocskyx96c0UY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUBH-xc5tb0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciI3q_zakWOS",
        "colab_type": "text"
      },
      "source": [
        "### Preparing Input data\n",
        "We need datasets to train models. In this example, we will create a small datasets using in-memory NumPy arrays to train and evaluate a model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjvwiYYhW4hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSo7qrwZlOrl",
        "colab_type": "text"
      },
      "source": [
        "### Training a model\n",
        "Finally, we can train the model using the `fit` method and then the model is \"fit\" to the training data. We can specify the training data to use (`data` and `labels`), how many epochs we will run (`epochs`), and how many items to be processed in a batch (`batch_size`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPOV-4VXk53s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "4954b8f3-b20a-4a7c-bf11-ef4647f0e374"
      },
      "source": [
        "model.fit(data, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 134us/sample - loss: 12.1009 - acc: 0.1140\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 46us/sample - loss: 11.9239 - acc: 0.1100\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 44us/sample - loss: 11.8161 - acc: 0.1140\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 48us/sample - loss: 11.7363 - acc: 0.1150\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 44us/sample - loss: 11.6779 - acc: 0.1300\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 49us/sample - loss: 11.6377 - acc: 0.1200\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 47us/sample - loss: 11.6065 - acc: 0.1460\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 48us/sample - loss: 11.5852 - acc: 0.1250\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 46us/sample - loss: 11.5689 - acc: 0.1200\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 49us/sample - loss: 11.5526 - acc: 0.1400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9bbac19710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4ORwtammNNb",
        "colab_type": "text"
      },
      "source": [
        "### Quiz 1.\n",
        "First, define a multi-layer model with \n",
        "  - 1 Dense layer with 10 units and `softmax` activation, taking input tensor of `(32,)` shape (hint: [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)).\n",
        "  - Another Dense layer with 10 units and `softmax` activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhKpYAgszdkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "############# Write here. #############\n",
        "#model = ...\n",
        "model = tf.keras.Sequential()\n",
        "layer1 = layers.Dense(10,input_shape=(32,))\n",
        "model.add(layer1)\n",
        "layer2 = layers.Dense(10,activation='softmax')\n",
        "model.add(layer2)\n",
        "#######################################\n",
        "model = tf.keras.Sequential([layers.Dense(10,input_shape=(32,)),layers.Dense(10,activation='softmax')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnL8eeL613b",
        "colab_type": "text"
      },
      "source": [
        "Using the model and `(data, labels)` above, let's train the model using the following configuration:\n",
        "* optimizer: `tf.train.RMSPropOptimizer`\n",
        "* learning rate: 0.001\n",
        "* loss: `categorical_crossentropy`\n",
        "* metrics: `accuracy`\n",
        "* batch size: 32\n",
        "* epochs: 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tNzWLWz0bj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "outputId": "05cdb9af-8d38-4e5d-ec06-5cd2502a949a"
      },
      "source": [
        "############# Write here. #############\n",
        "# model.compile(...)\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# model.fit(...) \n",
        "model.fit(data, labels, epochs=20, batch_size=32)\n",
        "#######################################\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 0s 123us/sample - loss: 12.3648 - acc: 0.0890\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 0s 44us/sample - loss: 11.8714 - acc: 0.0990\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 0s 41us/sample - loss: 11.6897 - acc: 0.0950\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 0s 43us/sample - loss: 11.6430 - acc: 0.0880\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 0s 41us/sample - loss: 11.6100 - acc: 0.0930\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 0s 42us/sample - loss: 11.5826 - acc: 0.0970\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 0s 43us/sample - loss: 11.5614 - acc: 0.1020\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 0s 44us/sample - loss: 11.5443 - acc: 0.0970\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 0s 44us/sample - loss: 11.5302 - acc: 0.1060\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 0s 44us/sample - loss: 11.5190 - acc: 0.1030\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 0s 44us/sample - loss: 11.5099 - acc: 0.1060\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 0s 43us/sample - loss: 11.5023 - acc: 0.1100\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 0s 46us/sample - loss: 11.4968 - acc: 0.1030\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 0s 49us/sample - loss: 11.4915 - acc: 0.1080\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 0s 40us/sample - loss: 11.4873 - acc: 0.1140\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 0s 45us/sample - loss: 11.4847 - acc: 0.1090\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 0s 40us/sample - loss: 11.4812 - acc: 0.1220\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 0s 40us/sample - loss: 11.4794 - acc: 0.1130\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 0s 42us/sample - loss: 11.4770 - acc: 0.1280\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 0s 44us/sample - loss: 11.4759 - acc: 0.1120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9bbaded278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLHgqqrmW2nJ",
        "colab_type": "text"
      },
      "source": [
        "## 2. Eager execution\n",
        "\n",
        "Eager execution is a flexible machine learning platform for research and experimentation, providing:\n",
        "\n",
        "* **An intuitive interface** Structure your code naturally and use Python data structures. Quickly iterate on small models and small data.\n",
        "* **Easier debugging** Call ops directly to inspect running models and test changes. Use standard Python debugging tools for immediate error reporting.\n",
        "* **Natural control flow** Use Python control flow instead of graph control flow, simplifying the specification of dynamic models.\n",
        "\n",
        "Eager execution supports most TensorFlow operations and GPU acceleration. For a collection of examples running in eager execution, see: tensorflow/contrib/eager/python/examples.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNfqm-LqvU8y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Setup\n",
        "\n",
        "To start eager execution, add `tf.enable_eager_execution()`\n",
        " to the **beginning** of the program or console session. In the jupyter (or colab) environment, you need to restart the runtime if the session has executed any command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp52QHc2vj0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "7b9c769e-3872-4079-8616-cda222fb300c"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2f19147a4fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[0;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[1;32m   5459\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5460\u001b[0m         \u001b[0mexecution_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5461\u001b[0;31m         server_def=None)\n\u001b[0m\u001b[1;32m   5462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[0;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[1;32m   5514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5515\u001b[0m       raise ValueError(\n\u001b[0;32m-> 5516\u001b[0;31m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0m\u001b[1;32m   5517\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5518\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZpmQwNYvRFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6c1de35a-3254-44c1-85e9-89c88bf9d7f4"
      },
      "source": [
        "# Checks whether the eager mode is used (True if enabled)\n",
        "tf.executing_eagerly()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0vlTsmKxSgu",
        "colab_type": "text"
      },
      "source": [
        "Unlike in the graph mode, all operations (e.g., constant, matrix multiplication) are returned directly. Recall that the operators are not executed until `Session.run()` and thus the values are not available even though we run statement in python-level.\n",
        "\n",
        "### Constants\n",
        "Instead, in the eager execution, the values are returned immediately. Let's start with constants that we defined at the previous sessions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CchaD-LnF1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "22b79977-e432-42ed-fdbf-5d8046256548"
      },
      "source": [
        "#constant of 1d tensor, or a vector\n",
        "a = tf.constant([2,2], name = 'vector')\n",
        "\n",
        "#constant of 2x2 tensor, or a matrix\n",
        "b = tf.constant([[0,2], [1,3]], name = 'matrix')\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# See what happens if you uncomment the last line\n",
        "#print(a.name)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 2], shape=(2,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 2]\n",
            " [1 3]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck-CzsbjUP5c",
        "colab_type": "text"
      },
      "source": [
        "We can see the results are printed. Obviously, the `name` field is not useful since we can now access the values in python code, so uncommenting the last line raises an error in `Tensor.name`.\n",
        "\n",
        "As you might notice, this way is simpler and more intuitive than in graph mode, where the value can be retrieved only when `session.run()` is called as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBLi8p3yV2cQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c44434da-06f9-4952-94ed-001d9477a20f"
      },
      "source": [
        "# In the graph mode, print(aa) prints only the metadata of aa\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  aa = tf.constant([2,2], name = 'vector')\n",
        "  print(aa.name)\n",
        "print(aa)\n",
        "  \n",
        "# The value of the aa can be obtained through sess.run(aa)\n",
        "with tf.Session(graph=graph) as sess:\n",
        "  print(sess.run(aa))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vector:0\n",
            "Tensor(\"vector:0\", shape=(2,), dtype=int32)\n",
            "[2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL3Sz4aGYpQg",
        "colab_type": "text"
      },
      "source": [
        "### Math Ops\n",
        "Eager execution also allows the mathmatical operations to be computed immediately. Let's take the same examples that we saw with the graph mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVLXaK3UXFqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "29af923a-2246-4bfc-cd69-0adc64fa35f2"
      },
      "source": [
        "div = tf.div(b, a)\n",
        "print(div)\n",
        "\n",
        "# See what happens if you uncomment the last line\n",
        "# print(div.op)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-b22c420db22c>:1: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "tf.Tensor(\n",
            "[[0 1]\n",
            " [0 1]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfLYTXCAZIF4",
        "colab_type": "text"
      },
      "source": [
        "Even better, TF eager execution supports operator overloading and numpy operations. See how the computation becomes easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nXofidfZDoj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "426100ee-df22-460e-a1fe-a1556f61e0b1"
      },
      "source": [
        "# Operator overloading\n",
        "print(b/a)\n",
        "\n",
        "# Numpy integration\n",
        "import numpy as np\n",
        "print(np.divide(b, a))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.  1. ]\n",
            " [0.5 1.5]], shape=(2, 2), dtype=float64)\n",
            "[[0.  1. ]\n",
            " [0.5 1.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-cE5TvAWgxr",
        "colab_type": "text"
      },
      "source": [
        "### Quiz 2.\n",
        "Define three 2x2 matrices (A, B, C) with the following values, and print the value of A x B + C (use eager execution)\n",
        "* A: [[3, 4], [2, 1]]\n",
        "* B: [[1,2], [1,2]]\n",
        "* C: [[-1,1],[4,1]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzZHCPpj9RwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "28901d59-779f-4334-957b-3423248513b1"
      },
      "source": [
        "########## Write here. ##########\n",
        "A = tf.constant([[3,4],[2,1]])\n",
        "B = tf.constant([[1,2],[1,2]])\n",
        "C = tf.constant([[-1,1],[4,1]])\n",
        "res = A*B + C\n",
        "res2 =  tf.add(tf.matmul(A,B),C)\n",
        "print(res)\n",
        "print(res2)\n",
        "\n",
        "##############################"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2 9]\n",
            " [6 3]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 6 15]\n",
            " [ 7  7]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lKERiI47yRI",
        "colab_type": "text"
      },
      "source": [
        "### Dynamic control flow\n",
        "\n",
        "A major benefit of eager execution is that all the functionality of the host language is available while your model is executing. So, for example, it is easy to write fizzbuzz game where any number divisible by three is replaced with the word \"fizz\", and any number divisible by five is replaced with the word \"buzz\" (similar to 3-6-9 game in Korea)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6VNGtHn0vIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "05e99d70-3b38-4c86-a62b-c767f8574d53"
      },
      "source": [
        "# Native python code\n",
        "def fizzbuzz(max_num):\n",
        "  counter = 0\n",
        "  for num in range(1, max_num+1):\n",
        "    if int(num % 3) == 0 and int(num % 5) == 0:\n",
        "      print('FizzBuzz')\n",
        "    elif int(num % 3) == 0:\n",
        "      print('Fizz')\n",
        "    elif int(num % 5) == 0:\n",
        "      print('Buzz')\n",
        "    else:\n",
        "      print(num)\n",
        "    counter += 1\n",
        "    \n",
        "fizzbuzz(20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "Fizz\n",
            "4\n",
            "Buzz\n",
            "Fizz\n",
            "7\n",
            "8\n",
            "Fizz\n",
            "Buzz\n",
            "11\n",
            "Fizz\n",
            "13\n",
            "14\n",
            "FizzBuzz\n",
            "16\n",
            "17\n",
            "Fizz\n",
            "19\n",
            "Buzz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4d4wnik07wk",
        "colab_type": "text"
      },
      "source": [
        "In eager execution, we need to add minor changes in a few lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4De2BYMb7tPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "432d2a5e-741e-4894-98ac-00622b01c497"
      },
      "source": [
        "import tensorflow as tf\n",
        "def fizzbuzz_eager(max_num):\n",
        "  counter = tf.constant(0) # counter = 0\n",
        "  max_num = tf.convert_to_tensor(max_num) #\n",
        "  for num in range(1, max_num.numpy()+1): #\n",
        "    num = tf.constant(num) # \n",
        "    if int(num % 3) == 0 and int(num % 5) == 0:\n",
        "      print('FizzBuzz')\n",
        "    elif int(num % 3) == 0:\n",
        "      print('Fizz')\n",
        "    elif int(num % 5) == 0:\n",
        "      print('Buzz')\n",
        "    else:\n",
        "      print(num.numpy()) # print(num)\n",
        "    counter += 1\n",
        "    \n",
        "fizzbuzz_eager(20)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "Fizz\n",
            "4\n",
            "Buzz\n",
            "Fizz\n",
            "7\n",
            "8\n",
            "Fizz\n",
            "Buzz\n",
            "11\n",
            "Fizz\n",
            "13\n",
            "14\n",
            "FizzBuzz\n",
            "16\n",
            "17\n",
            "Fizz\n",
            "19\n",
            "Buzz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASf7wXXOqoFU",
        "colab_type": "text"
      },
      "source": [
        "I searched *fizzbuzz in tensorflow graph* in Google and found a blog post [Tensorflow FizzBuzz Revisited (Ricky Han blog)](https://rickyhan.com/jekyll/update/2018/02/16/tensorflow-fizzbuzz-revisited.html) that shows how the above code can be written in TF graph mode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb4AqjBIsHWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "176ed71a-c6b8-4fbb-b7af-3582cb44dcbb"
      },
      "source": [
        "import tensorflow as tf\n",
        "def fizzbuzz_graph(max_num):\n",
        "  # Define variable and while_loop\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default():\n",
        "    arr = tf.Variable([str(i) for i in range(1, max_num+1)])\n",
        "    while_op = tf.while_loop(\n",
        "      (lambda i, _: tf.less(i, max_num+1)), \n",
        "      (lambda i, _: (tf.add(i,1), tf.cond(\n",
        "          tf.logical_and(tf.equal(tf.mod(i, 3), 0), tf.equal(tf.mod(i, 5), 0)),\n",
        "          (lambda : tf.assign(arr[(i - 1)], 'FizzBuzz')),\n",
        "          (lambda : tf.cond(tf.equal(tf.mod(i, 3), 0),\n",
        "              (lambda : tf.assign(arr[(i - 1)], 'Fizz')),\n",
        "              (lambda : tf.cond(tf.equal(tf.mod(i, 5), 0),\n",
        "                  (lambda : tf.assign(arr[(i - 1)], 'Buzz')),\n",
        "                  (lambda : arr)))))))),\n",
        "      [1, arr])\n",
        "  # Call Session.run()\n",
        "  with tf.Session(graph = graph) as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      idx, array = sess.run(while_op)\n",
        "      print(array)\n",
        "      \n",
        "fizzbuzz_graph(100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'1' b'2' b'Fizz' b'4' b'Buzz' b'Fizz' b'7' b'8' b'Fizz' b'Buzz' b'11'\n",
            " b'Fizz' b'13' b'14' b'FizzBuzz' b'16' b'17' b'Fizz' b'19' b'Buzz' b'Fizz'\n",
            " b'22' b'23' b'Fizz' b'Buzz' b'26' b'Fizz' b'28' b'29' b'FizzBuzz' b'31'\n",
            " b'32' b'Fizz' b'34' b'Buzz' b'Fizz' b'37' b'38' b'Fizz' b'Buzz' b'41'\n",
            " b'Fizz' b'43' b'44' b'FizzBuzz' b'46' b'47' b'Fizz' b'49' b'Buzz' b'Fizz'\n",
            " b'52' b'53' b'Fizz' b'Buzz' b'56' b'Fizz' b'58' b'59' b'FizzBuzz' b'61'\n",
            " b'62' b'Fizz' b'64' b'Buzz' b'Fizz' b'67' b'68' b'Fizz' b'Buzz' b'71'\n",
            " b'Fizz' b'73' b'74' b'FizzBuzz' b'76' b'77' b'Fizz' b'79' b'Buzz' b'Fizz'\n",
            " b'82' b'83' b'Fizz' b'Buzz' b'86' b'Fizz' b'88' b'89' b'FizzBuzz' b'91'\n",
            " b'92' b'Fizz' b'94' b'Buzz' b'Fizz' b'97' b'98' b'Fizz' b'Buzz']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqWzzFUO79nx",
        "colab_type": "text"
      },
      "source": [
        "### Model Subclassing\n",
        "We can build a fully-customizable model by subclassing [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) and defining your own forward pass. Layers are created in the `__init__` method and they are set as attributes of the class instance. The forward pass is defined in the `call` method. Model subclassing is particularly useful when eager execution is enabled since the forward pass can be written imperatively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ3w_EmG7shn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNISTModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    \"\"\"Define layers\"\"\"\n",
        "    super(MNISTModel, self).__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(units=10)\n",
        "    self.dense2 = tf.keras.layers.Dense(units=10)\n",
        "\n",
        "  def call(self, input):\n",
        "    \"\"\"Define forward pass.\"\"\"\n",
        "    result = self.dense1(input)\n",
        "    result = self.dense2(result)\n",
        "    result = self.dense2(result)  # reuse variables from dense2 layer\n",
        "    return result\n",
        "\n",
        "model = MNISTModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8MEnHhAvskB",
        "colab_type": "text"
      },
      "source": [
        "It's not required to set an input shape for the `tf.keras.Model` class since the parameters are set the first time input is passed to the layer.\n",
        "\n",
        "tf.keras.layers classes create and contain their own model variables that are tied to the lifetime of their layer objects. To share layer variables, share their objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNwIJ58cvy2n",
        "colab_type": "text"
      },
      "source": [
        "### Eager training\n",
        "\n",
        "Automatic differentiation is useful for implementing machine learning algorithms such as backpropagation for training neural networks. During eager execution, use tf.GradientTape to trace operations for computing gradients later.\n",
        "\n",
        "tf.GradientTape is an opt-in feature to provide maximal performance when not tracing. Since different operations can occur during each call, all forward-pass operations get recorded to a \"tape\". To compute the gradient, play the tape backwards and then discard. A particular tf.GradientTape can only compute one gradient; subsequent calls throw a runtime error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "embmV_cFv4Bq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7e5051b1-da9a-40f2-c62a-42f5bf0cda3c"
      },
      "source": [
        "w = tf.Variable([[1.0]])\n",
        "with tf.GradientTape() as tape:\n",
        "  loss = w * w\n",
        "\n",
        "grad = tape.gradient(loss, w)\n",
        "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opVbDRRvwVkP",
        "colab_type": "text"
      },
      "source": [
        "Below is an example of a linear regression model to be defined as a subclass of `tf.keras.Model`, and then be trained using loss and gradient function, which is defined imperatively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK6nhzcivyPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    \"\"\"Define layers\"\"\"\n",
        "    super(Model, self).__init__()\n",
        "    self.W = tf.Variable(5., name='weight')\n",
        "    self.B = tf.Variable(10., name='bias')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    \"\"\"Define forward pass\"\"\"\n",
        "    return inputs * self.W + self.B\n",
        "\n",
        "# The loss function to be optimized\n",
        "def loss(model, inputs, targets):\n",
        "  error = model(inputs) - targets\n",
        "  return tf.reduce_mean(tf.square(error))\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets)\n",
        "  return tape.gradient(loss_value, [model.W, model.B])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhNlE5mTw7bX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "d53f7824-b5cb-4274-b75e-4eca1c75e49f"
      },
      "source": [
        "# Instantiate the model and an optimizer to use.\n",
        "model = Model()\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "\n",
        "\n",
        "# Let's train with a toy dataset of points around 3 * x + 2\n",
        "NUM_EXAMPLES = 2000\n",
        "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
        "noise = tf.random_normal([NUM_EXAMPLES])\n",
        "training_outputs = training_inputs * 3 + 2 + noise\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "# Training loop\n",
        "for i in range(300):\n",
        "  grads = grad(model, training_inputs, training_outputs)\n",
        "  optimizer.apply_gradients(zip(grads, [model.W, model.B]),\n",
        "                            global_step=tf.train.get_or_create_global_step())\n",
        "  if i % 20 == 0:\n",
        "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
        "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial loss: 68.693\n",
            "Loss at step 000: 66.015\n",
            "Loss at step 020: 29.999\n",
            "Loss at step 040: 13.932\n",
            "Loss at step 060: 6.765\n",
            "Loss at step 080: 3.567\n",
            "Loss at step 100: 2.141\n",
            "Loss at step 120: 1.504\n",
            "Loss at step 140: 1.220\n",
            "Loss at step 160: 1.094\n",
            "Loss at step 180: 1.037\n",
            "Loss at step 200: 1.012\n",
            "Loss at step 220: 1.001\n",
            "Loss at step 240: 0.996\n",
            "Loss at step 260: 0.994\n",
            "Loss at step 280: 0.993\n",
            "Final loss: 0.992\n",
            "W = 3.047919988632202, B = 2.0220162868499756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOowIsLDs7J_",
        "colab_type": "text"
      },
      "source": [
        "## Wrap-up\n",
        "\n",
        "So far, we have learned how we can use two types of high-level APIs: Keras and eager execution. For more information about Keras and Eager execution, you can visit https://www.tensorflow.org/guide/keras and https://www.tensorflow.org/guide/eager, respectively (and many other blog posts as well!).\n",
        "\n",
        "Next week, we will build a Deep Reinforcement Learning application using these APIs.\n"
      ]
    }
  ]
}